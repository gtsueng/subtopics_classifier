{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtopics classifier for multiple resouce types\n",
    "\n",
    "Because there are over 25 'subcategories' in the outbreak.info topicCategories, it is difficult automatically create large enough training datasets for each of them.  For this reason, it is necessary to pool the data from curate.outbreak.info and the clinical trials classifier as well as from litcovid as identified via keyword mapping in order to generate a large enough training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries and generate the datapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from src.classify_pubs import *\n",
    "from src.common import load_classifiers\n",
    "\n",
    "#### MAIN\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "#try:\n",
    "#    general_path = pathlib.Path(__file__).parents[1].absolute()\n",
    "#except:\n",
    "#    general_path = pathlib.Path(__file__).resolve().parents[1].absolute()\n",
    "\n",
    "script_path = os.path.abspath('')\n",
    "general_path = os.path.abspath(os.path.join(os.getcwd(),\"../\"))\n",
    "\n",
    "DATAPATH = os.path.join(script_path,'data/')\n",
    "RESULTSPATH = os.path.join(script_path,'results/')\n",
    "MODELPATH = os.path.join(script_path,'models/')\n",
    "PREDICTPATH = os.path.join(script_path,'predictions/')\n",
    "\n",
    "littopicsfile = os.path.join(DATAPATH,'litcovidtopics.tsv')\n",
    "offtopicsfile = os.path.join(DATAPATH,'othertopics.tsv')\n",
    "littopicsdf = read_csv(littopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "offtopicsdf = read_csv(offtopicsfile,delimiter='\\t',header=0,index_col=0)\n",
    "topicsdf = pd.concat((littopicsdf,offtopicsdf),ignore_index=True)\n",
    "topiclist = topicsdf['topicCategory'].unique().tolist()\n",
    "litsubtopicsfile = os.path.join(DATAPATH,'subtopics.tsv')\n",
    "litsubtopics = read_csv(litsubtopicsfile,delimiter='\\t',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the data from litcovid keyword mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATAPATH,'updated_pmids_for_training.pickle'),'rb') as litfile:\n",
    "    litkeytopics = pickle.load(litfile)\n",
    "\n",
    "keysubtopics = litkeytopics.loc[litkeytopics['subcategory']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the litcovid training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antibody Detection', 'Pathology/Radiology', 'Rapid Diagnostics', 'Symptoms', 'Testing Prevalence', 'Virus Detection', 'Classical epidemiology', 'Molecular epidemiology', 'Host Factors', 'Immunological Response', 'Mechanism of Infection', 'Mechanism of Transmission', 'Virus Factors', 'Individual Prevention', 'Public Health Interventions', 'Host/Intermediate Reservoirs', 'Viral Shedding/Persistence', 'Biologics', 'Medical Care', 'Pharmaceutical Treatments', 'Prognosis', 'Repurposing', 'Vaccines']\n"
     ]
    }
   ],
   "source": [
    "litsubtopics['topicCategory'] = litsubtopics['topicCategory'].astype(str).str.replace('-','/')\n",
    "print(litsubtopics['topicCategory'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case Descriptions', 'Risk Factors', 'Antibody Detection', 'Pathology/Radiology', 'Rapid Diagnostics', 'Symptoms', 'Testing Prevalence', 'Virus Detection', 'Classical epidemiology', 'Molecular epidemiology', 'Host Factors', 'Immunological Response', 'Mechanism of Infection', 'Mechanism of Transmission', 'Virus Factors', 'Individual Prevention', 'Public Health Interventions', 'Host/Intermediate Reservoirs', 'Viral Shedding/Persistence', 'Biologics', 'Medical Care', 'Pharmaceutical Treatments', 'Repurposing', 'Vaccines']\n"
     ]
    }
   ],
   "source": [
    "boom = keysubtopics.explode('matching_pmids')\n",
    "boom.rename(columns={'matching_pmids':'_id'},inplace=True)\n",
    "boom_clean = boom[['_id','topicCategory']].copy()\n",
    "boom_clean['topicCategory'] = boom_clean['topicCategory'].astype(str).str.replace(' / ','/')\n",
    "print(boom_clean['topicCategory'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144130\n",
      "Wall time: 10min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.common import *\n",
    "\n",
    "pmidlist = list(set(boom_clean['_id'].unique().tolist()).union(set(litsubtopics['_id'].unique().tolist())))\n",
    "textdf = batch_fetch_meta(pmidlist)\n",
    "textdf = merge_texts(textdf)\n",
    "clean_textdf = textdf[['_id','text']]\n",
    "combidf = pd.concat((boom_clean,litsubtopics[['_id','topicCategory']]),ignore_index=True)\n",
    "litmergeddf = combidf.merge(textdf,on='_id',how='left')\n",
    "print(len(litmergeddf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the data from curate.outbreak.info\n",
    "Note that PDB datasets generally have very little by way of useful description and will generally be categorized as host factors (in the case of a human protein) or virus factors (when it's about virus proteins). Due to the overall/general lack of useful text in PDB records, they should be omitted from the training data since they generally won't provide much info to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                _id                                               text  \\\n",
      "0  figshare11752752  comparative model of novel coronavirus 2019 nc...   \n",
      "1  figshare11806065  prisma scoping review checklist for nowak and ...   \n",
      "\n",
      "               topicCategory  \n",
      "0              Virus Factors  \n",
      "1  Pharmaceutical Treatments  \n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(general_path,'curate_outbreak_data/results/curated_training_df.pickle'),'rb') as curate_file:\n",
    "    curate_data = pickle.load(curate_file)\n",
    "\n",
    "curate_df = curate_data[['_id','text','category']].copy()\n",
    "curate_df.rename(columns={'category':'topicCategory'},inplace=True)\n",
    "print(curate_df.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the data from clinical trials\n",
    "Note that the CT data was saved along with name, abstract, description, and text so it is ready to use in the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12086\n",
      "7088\n"
     ]
    }
   ],
   "source": [
    "ct_classified = os.path.join(general_path,'outbreak_CT_classifier/data/topicCategories/')\n",
    "ct_training_files = os.listdir(ct_classified)\n",
    "\n",
    "ct_subtopics = pd.DataFrame(columns = ['_id','text','topicCategory'])\n",
    "for eachfile in ct_training_files:\n",
    "    category = eachfile.replace('.pickle','')\n",
    "    with open(os.path.join(ct_classified,eachfile),\"rb\") as tmpfile:\n",
    "        tmpdata = pickle.load(tmpfile)\n",
    "    tmpdata['topicCategory'] = category.replace('_','/')\n",
    "    cleandata = tmpdata[['_id','text','topicCategory']].copy()\n",
    "    ct_subtopics = pd.concat((ct_subtopics,cleandata),ignore_index=True)\n",
    "print(len(ct_subtopics))\n",
    "ct_subtopics.drop_duplicates(keep='first',inplace=True)\n",
    "print(len(ct_subtopics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              _id  counts\n",
      "2493  NCT04516512       6\n",
      "1510  NCT04377802       6\n",
      "1988  NCT04429724       5\n",
      "1816  NCT04408456       5\n",
      "3024  NCT04616846       5\n",
      "               _id                                               text  \\\n",
      "185    NCT04516512  sars cov 2 seroprevalence among adults people ...   \n",
      "1021   NCT04516512  sars cov 2 seroprevalence among adults people ...   \n",
      "1325   NCT04516512  sars cov 2 seroprevalence among adults people ...   \n",
      "6210   NCT04516512  sars cov 2 seroprevalence among adults people ...   \n",
      "6739   NCT04516512  sars cov 2 seroprevalence among adults people ...   \n",
      "12051  NCT04516512  sars cov 2 seroprevalence among adults people ...   \n",
      "\n",
      "            topicCategory  \n",
      "185    Antibody Detection  \n",
      "1021            Biologics  \n",
      "1325            Diagnosis  \n",
      "6210    Rapid Diagnostics  \n",
      "6739             Symptoms  \n",
      "12051     Virus Detection  \n"
     ]
    }
   ],
   "source": [
    "ct_subtopics_freq = ct_subtopics.groupby('_id').size().reset_index(name='counts')\n",
    "ct_subtopics_freq.sort_values('counts',ascending=False,inplace=True)\n",
    "print(ct_subtopics_freq.head(n=5))\n",
    "print(ct_subtopics.loc[ct_subtopics['_id']=='NCT04516512'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antibody Detection', 'Behavioral Research', 'Biologics', 'Case Descriptions', 'Diagnosis', 'Host Factors', 'Individual Prevention', 'Medical Care', 'Pathology-Radiology', 'Pharmaceutical Treatments', 'Prevention', 'Public Health Interventions', 'Rapid Diagnostics', 'Repurposing', 'Symptoms', 'Treatment', 'Vaccines', 'Virus Detection', 'Virus Factors', 'Viral Shedding-Persistence', 'Clinical', 'Mechanism of Infection', 'Transmission', 'Mechanism', 'Epidemiology', 'Forecasting', 'Risk Factors', 'Immunological Response', 'Classical epidemiology', 'Host-Intermediate Reservoirs', 'Mechanism of Transmission', 'Molecular epidemiology', 'Testing Prevalence', 'Prognosis']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "allsubtopicsdf = pd.concat((ct_subtopics,curate_df,litmergeddf),ignore_index=True)\n",
    "allsubtopicsdf['topicCategory'] = allsubtopicsdf['topicCategory'].astype(str).str.replace('/','-')\n",
    "allsubtopicsdf['topicCategory'] = allsubtopicsdf['topicCategory'].astype(str).str.replace(' - ','-')\n",
    "print(allsubtopicsdf['topicCategory'].unique().tolist())\n",
    "subtopics_only = allsubtopicsdf.loc[~allsubtopicsdf['topicCategory'].isin(topiclist)] \n",
    "print(len(subtopics_only['topicCategory'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up and export the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common import *\n",
    "training_to_export = allsubtopicsdf[['_id','topicCategory']].copy()\n",
    "training_to_export.drop_duplicates(keep='first',inplace=True)\n",
    "training_to_export['topicCategory'] = training_to_export['topicCategory'].astype(str).str.replace('-','/')\n",
    "cleanresults = clean_results(training_to_export)\n",
    "cleanresults.to_csv(os.path.join(RESULTSPATH,'topicCats.tsv'),mode='w',sep='\\t',header=True)\n",
    "print(cleanresults.tail(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_models(MODELPATH,subtopicsdf,classifiers,traintopics=\"all\"):\n",
    "    breakdown = subtopicsdf.groupby('topicCategory').size().reset_index(name='counts')\n",
    "    if traintopics != \"all\":\n",
    "        eachtopic = traintopics\n",
    "        trainingset = generate_training_df(subtopicsdf,eachtopic)\n",
    "        X = generate_vectorizer(MODELPATH,trainingset,eachtopic)\n",
    "        for eachclassifier in classifiers.keys():\n",
    "            classifier=classifiers[eachclassifier]\n",
    "            classifier.fit(X, trainingset.target)\n",
    "            save_model(MODELPATH,classifier,eachclassifier,eachtopic)     \n",
    "    else:\n",
    "        for eachtopic in breakdown['topicCategory'].tolist():\n",
    "            trainingset = generate_training_df(subtopicsdf,eachtopic)\n",
    "            X = generate_vectorizer(MODELPATH,trainingset,eachtopic)\n",
    "            for eachclassifier in classifiers.keys():\n",
    "                classifier=classifiers[eachclassifier]\n",
    "                classifier.fit(X, trainingset.target)\n",
    "                save_model(MODELPATH,classifier,eachclassifier,eachtopic)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from src.train_classifier import *  \n",
    "\n",
    "classifiers = load_classifiers('best')\n",
    "generate_models(MODELPATH,subtopics_only,classifiers,\"all\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subtopics_only['topicCategory'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sub_test(RESULTPATH,subtopicsdf,classifierset_type='best',export_report=False):\n",
    "    classifiers = load_classifiers(classifierset_type)\n",
    "    breakdown = subtopicsdf.groupby('topicCategory').size().reset_index(name='counts')\n",
    "    testresults = []\n",
    "    for eachtopic in breakdown['topicCategory'].tolist():\n",
    "        print(\"now testing: \",eachtopic,datetime.now())\n",
    "        training_set = generate_training_df(subtopicsdf,eachtopic)\n",
    "        X = vectorize_text(training_set)\n",
    "        for classifier in classifiers.keys():\n",
    "            i=0\n",
    "            while i<5:\n",
    "                timestart = datetime.now()\n",
    "                cmresult,report,auc = train_test_classify(classifiers[classifier],training_set,X,i)\n",
    "                runtime = datetime.now() - timestart\n",
    "                testresults.append({'topicCategory':eachtopic,'set size':len(training_set),'classifier':classifier,\n",
    "                                    'runtime':runtime,'auc':auc,'report':report,'matrix':cmresult,'i':i})\n",
    "                i=i+1\n",
    "    testresultsdf = pd.DataFrame(testresults)\n",
    "    if export_report==True:\n",
    "        testresultsdf.to_csv(os.path.join(RESULTPATH,'in_depth_classifier_test.tsv'),sep='\\t',header=True)\n",
    "    return(testresultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyze and validate the models\n",
    "testresultsdf = run_sub_test(RESULTSPATH,subtopics_only,classifierset_type='best',export_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the classifications and check the results\n",
    "Use the existing models to run classification predictions on:\n",
    "1. Clinical Trials\n",
    "    * The original mapping system can be used to validate the accuracy of the predictions\n",
    "2. Preprints and new LitCovid entries\n",
    "    * Sanity/spot check results\n",
    "3. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classify_pubs import *\n",
    "from src.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = load_classifiers('best')\n",
    "classifierlist = classifiers.keys()\n",
    "subtopiclist = subtopics_only['topicCategory'].unique().tolist()\n",
    "print(subtopiclist)\n",
    "print(len(subtopiclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5584 0\n",
      "Wall time: 21.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Load Clinical Trials records which have name, abstract, text\n",
    "## But do NOT have info on primary design purpose, or intervention\n",
    "with open(os.path.join(general_path,'outbreak_CT_classifier/data/blank_entries.pickle'),'rb') as unclassified:\n",
    "    ct_to_classify = pickle.load(unclassified)\n",
    "\n",
    "subtopiclist = subtopics_only['topicCategory'].unique().tolist()\n",
    "predict_class(MODELPATH,PREDICTPATH,subtopiclist,classifierlist,ct_to_classify,newonly = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   _id                                      topicCategory\n",
      "0  ACTRN12620000617965  [Individual Prevention, Public Health Interven...\n",
      "1  CTRI/2020/04/024413  [Individual Prevention, Public Health Interven...\n",
      "2  CTRI/2020/04/024479  [Biologics, Medical Care, Pharmaceutical Treat...\n",
      "3  CTRI/2020/04/024659             [Biologics, Pharmaceutical Treatments]\n",
      "4  CTRI/2020/04/024706             [Biologics, Pharmaceutical Treatments]\n",
      "Wall time: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_agree = merge_predictions(PREDICTPATH,subtopiclist,classifierlist,agreetype='perfect')\n",
    "allresults = total_agree.merge(ct_to_classify,on='_id',how='inner')\n",
    "cleanresults = clean_results(allresults)\n",
    "print(cleanresults.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_map={'Pathology/Radiology':['graphy','ultrasound','ECG','Pulmonary Function Test','Spirometry','biopsy'],\n",
    "          'Rapid Diagnostics':['rapid','Rapid'],\n",
    "          'Virus Detection':['RT-PCR','PCR'],\n",
    "          'Antibody Detection':['antibod','Antibod','antigen','Anti-SARS-CoV2','Antigen','ELISA','ELISPOT'],\n",
    "          'Symptoms':['symptom','clinical sign','presenting with','clinical presentation'],\n",
    "          'Vaccines':['vaccin','Vaccin','inactivated virus'],\n",
    "                     'Medical Care':['Ventilat','ventilat','standard of care','soc','s.o.c.'],\n",
    "          'Public Health Interventions':['policy','travel restriction','lockdown','quarantine','campaign','closures'],\n",
    "          'Individual Prevention':['counsel','training','education','awareness','PPE','face mask','face covering','device'],\n",
    "          'Vaccines':['vaccin','Vaccin','inactivated virus']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "tmpresults = []\n",
    "for eachkey in misc_map.keys():\n",
    "    keywordlist = misc_map[eachkey]\n",
    "    topicCategory = eachkey\n",
    "    searchregex = re.compile('|'.join(keywordlist), re.IGNORECASE)\n",
    "    tmpdf = allresults.loc[((allresults['interventionName'].str.contains(searchregex))|\n",
    "                          (allresults['text'].str.contains(searchregex)))]\n",
    "    unique_ids = len(tmpdf['_id'].unique().tolist())\n",
    "    predicted_df = allresults.loc[allresults['topicCategory']==topicCategory.replace('/','-')]\n",
    "    matching_ids = list(set(predicted_df['_id'].unique().tolist()).intersection(set(tmpdf['_id'].unique().tolist())))\n",
    "    algo_not_in_regex = [x for x in predicted_df['_id'].unique().tolist() if x not in tmpdf['_id'].unique().tolist()]\n",
    "    regex_not_in_algo = [x for x in tmpdf['_id'].unique().tolist() if x not in predicted_df['_id'].unique().tolist()]\n",
    "    tmpresults.append({'topicCategory':topicCategory,\n",
    "                       'ids_found_via_regex':unique_ids,\n",
    "                       'ids_found_via_algorithm':len(predicted_df['_id'].unique().tolist()),\n",
    "                       'ids_matching_both':len(matching_ids),\n",
    "                       'regex_percent_pos':len(matching_ids)/unique_ids,\n",
    "                       'algo_percent_pos':len(matching_ids)/len(predicted_df['_id'].unique().tolist()),\n",
    "                       'ids_in_algo_not_regex':len(algo_not_in_regex),\n",
    "                       'ids_in_regex_not_algo':len(regex_not_in_algo),\n",
    "                       'algo_id_list':predicted_df['_id'].unique().tolist(),\n",
    "                       'algo_not_in_reg':algo_not_in_regex,\n",
    "                       'regex_id_list':matching_topics['_id'].unique().tolist(),\n",
    "                       'regex_not_in_algo':regex_not_in_algo\n",
    "                      })\n",
    "resultdf = pd.DataFrame(tmpresults)\n",
    "resultdf.to_csv('results/nonNCT_clinical_trial_check.tsv',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean up the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
